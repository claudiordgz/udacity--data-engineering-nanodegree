{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Spark SQL Quiz\n",
    "\n",
    "This quiz uses the same dataset and most of the same questions from the earlier \"Quiz - Data Wrangling with Data Frames Jupyter Notebook.\" For this quiz, however, use Spark SQL instead of Spark Data Frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|       artist|     auth|firstName|gender|itemInSession|lastName|   length|level|            location|method|    page| registration|sessionId|                song|status|           ts|           userAgent|userId|\n",
      "+-------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "|Showaddywaddy|Logged In|  Kenneth|     M|          112|Matthews|232.93342| paid|Charlotte-Concord...|   PUT|NextSong|1509380319284|     5132|Christmas Tears W...|   200|1513720872284|\"Mozilla/5.0 (Win...|  1046|\n",
      "|   Lily Allen|Logged In|Elizabeth|     F|            7|   Chase|195.23873| free|Shreveport-Bossie...|   PUT|NextSong|1512718541284|     5027|       Cheryl Tweedy|   200|1513720878284|\"Mozilla/5.0 (Win...|  1000|\n",
      "+-------------+---------+---------+------+-------------+--------+---------+-----+--------------------+------+--------+-------------+---------+--------------------+------+-------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODOS: \n",
    "# 1) import any other libraries you might need\n",
    "# 2) instantiate a Spark session \n",
    "# 3) read in the data set located at the path \"data/sparkify_log_small.json\"\n",
    "# 4) create a view to use with your SQL queries\n",
    "# 5) write code to answer the quiz questions \n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Data wrangling with Spark SQL\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "path = \"data/sparkify_log_small.json\"\n",
    "user_log = spark.read.json(path)\n",
    "\n",
    "user_log.createOrReplaceTempView(\"user_log_table\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM user_log_table LIMIT 2\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Which page did user id \"\"(empty string) NOT visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----+\n",
      "|            page|page|\n",
      "+----------------+----+\n",
      "|Submit Downgrade|null|\n",
      "|       Downgrade|null|\n",
      "|          Logout|null|\n",
      "|   Save Settings|null|\n",
      "|        Settings|null|\n",
      "|        NextSong|null|\n",
      "|         Upgrade|null|\n",
      "|           Error|null|\n",
      "|  Submit Upgrade|null|\n",
      "+----------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 1\n",
    "spark.sql('''\n",
    "    SELECT *\n",
    "    FROM (  \n",
    "        SELECT DISTINCT page FROM user_log_table\n",
    "    ) AS all_pages\n",
    "    LEFT JOIN (\n",
    "        SELECT DISTINCT page\n",
    "        FROM user_log_table\n",
    "        WHERE userID = ''    \n",
    "    ) AS user_pages\n",
    "    ON user_pages.page = all_pages.page\n",
    "    WHERE user_pages.page IS NULL\n",
    "    ''').show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Reflect\n",
    "\n",
    "Why might you prefer to use SQL over data frames? Why might you prefer data frames over SQL?\n",
    "\n",
    "## SQL over data frames\n",
    "\n",
    "  - SQL is easier to read\n",
    "  \n",
    "## Data frames over SQL\n",
    "  \n",
    "  - This SQL has two nested queries, which right now are simple, but might get large over time. Using dataframes this behavior can be broken apart. After that you can unit test each nested behavior to make sure it returns the expected dataframe, which gives you reduced risk when releasing to production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "How many female users do we have in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|     462|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 3\n",
    "spark.sql('''\n",
    "    SELECT COUNT(*)\n",
    "    FROM (\n",
    "        SELECT DISTINCT userId, gender FROM user_log_table\n",
    "    ) AS unique_users\n",
    "    WHERE unique_users.gender = 'F'\n",
    "    ''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "How many songs were played from the most played artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|  artist|plays|\n",
      "+--------+-----+\n",
      "|Coldplay|   83|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: write your code to answer question 4\n",
    "spark.sql('''\n",
    "    SELECT artist, count(artist) as plays\n",
    "    FROM user_log_table\n",
    "    GROUP BY artist\n",
    "    ORDER BY plays desc\n",
    "    LIMIT 1\n",
    "    ''').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (challenge)\n",
    "\n",
    "How many songs do users listen to on average between visiting our home page? Please round your answer to the closest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write your code to answer question 5\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
